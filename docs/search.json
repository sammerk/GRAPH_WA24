[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GRAPH Winterakademie",
    "section": "",
    "text": "Willkommen\nHier finden sich\n\nVideos,\nAufgaben,\nDaten und\nCode\n\nfür unseren Kurs Quantitative Datenanalyse für Fortgeschrittene. Da ich durch eine Verschiebung von Kommissionsterminen leider erst Donnerstag Abend anreisen kann, bitte ich ich alle Teilnehmer:innen vorab das erste Kapitel Einfache und multiple Regression durchzuarbeiten. Dort finden sich Videos und Aufgaben diesbezüglich.",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "1  Regressionsmodelle",
    "section": "",
    "text": "1.1 Einfache lineare Regression\nIn diesem Unterkapitel soll in die einfache lineare Regression eingeführt werden. Dazu dient ein Erklärvideo gefolgt von Aufgaben.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#einfache-lineare-regression",
    "href": "regression.html#einfache-lineare-regression",
    "title": "1  Regressionsmodelle",
    "section": "",
    "text": "1.1.1 Erklärvideo\n\n\n\n\n\n\n\n\n\n\n\nDatengrundlage\n\n\n\n\n\nWir werden in diesen Workshop mit den Scientific Usefiles des STAR-Projektes (Achilles u. a. 1985) arbeiten. Im STAR-Projekt standen die folgenden Forschungsfragen im Vordergrund:\n\nWhat are the effects of a reduced class size on the achievement (normed and criterion tests) and development (self-concept, attendance, etc.) of students in public elementary school grades (K-3)?\nIs there a cumulative effects of being in a small class over an extended time (4 years) as compared with a one-year effect for students in a small class for one year?\nDoes a training program designed to help teachers take maximum advantage of small classes, or to use aides effectively, improve student performance as compared with teachers who have no special preparation for their altered conditions?\n\nDie entsprechenden Variablenbezeichnungen sowie die Kodierung der Variablenausprägungen werden in den jeweiligen Beispielen beschrieben.\n\n\n\n\n\n1.1.2 Worked Out Example\nIm ersten Worked Out Example wollen wir der Frage nachgehen, inwiefern die tatsächliche Klassengröße mit der Leistung in einem standardisierten Mathematiktest assoziiert ist.\n\n1.1.2.1 Plot\nIn einem ersten Schritt (der ganz generell im zu empfehlen ist) plotten wir die Rohdaten. Um keine Probleme mit geclusterten Daten zu bekommen, verwenden wir aus jeder Klasse nur eine:n zufällig gezogenen Schüler:in. Ein .sav-file, das die notwendigen Variablen enthält, kann hier heruntergeladen werden.\n\nlibrary(sjPlot)\nlibrary(bayestestR)\n\n# read the aggregated data\ndata_star_g3aggregated &lt;- read_spss(\"data/data_star_sampled.sav\")\n\n# plot rawdata\nggplot(data_star_g3aggregated,                       # the used data set\n       aes(g3classsize, g3tmathss)) +                # define x- and y-axis\n    geom_jitter() +                                  # add jittered points\n    geom_rug(position = position_jitter(), \n             alpha = .2) +                           # add rug at margins\n    stat_smooth(method = \"linear\") +                 # add linear smoother\n    theme_minimal()                                  # make appearance \"clearer\"\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 37 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error in `get()`:\n! object 'linear' of mode 'function' was not found\n\n\nWarning: Removed 37 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n1.1.2.2 Nicht-Standardisierte Regression\nUm nun eine einfache lineare Regression zu schätzen, verwendet man in R die lm() Syntax. Links der Tilde ~ steht die abhängige Variable, rechts davon die unabhängige.\n\nmod00 &lt;- lm(g3tmathss ~ g3classsize, \n            data = data_star_g3aggregated)\n\nEine Übersicht über das Modell bekommt man, wenn man das Objekt mod00 der der Funktion summary() übergibt.\n\nsummary(mod00)\n\n\nCall:\nlm(formula = g3tmathss ~ g3classsize, data = data_star_g3aggregated)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-109.454  -29.725   -0.446   28.743  102.955 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 642.8773    10.1681  63.225   &lt;2e-16 ***\ng3classsize  -0.9015     0.4939  -1.825   0.0689 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.54 on 298 degrees of freedom\n  (37 observations deleted due to missingness)\nMultiple R-squared:  0.01106,   Adjusted R-squared:  0.007739 \nF-statistic: 3.332 on 1 and 298 DF,  p-value: 0.06895\n\n\nDie (lineare) Funktionsgleichung kann man sich mit der Funktion extract_eq() aus dem Paket equatiomatic ausgeben lassen. Mit der Option use_coefs = T setzt man die geschätzten Werte für die Parameter ein.\n\nlibrary(equatiomatic)\nextract_eq(mod00)\n\n\\[\n\\operatorname{g3tmathss} = \\alpha + \\beta_{1}(\\operatorname{g3classsize}) + \\epsilon\n\\]\n\nextract_eq(mod00, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{g3tmathss}} = 642.88 - 0.9(\\operatorname{g3classsize})\n\\]\n\n\nDer Steigungskoeffizient beträgt \\(\\approx .99\\). Unterscheiden sich zwei Klassen um eine:n Schüler:in schätzt das Modell die Differenz im Mathematikscore auf \\(-.99\\). Das Intercept wird auf \\(638.9\\) geschätzt. Eine (hypothetische) Klasse mit 0 Schüler:innen hätte also einen Durchschnittlichen Mathematikleistungsscore von \\(638.9\\).\nDie drei Sternchen am rechten Rand des summary() Outputs zeigen an, dass p-Werte für die Punktnullhypothesen \\[\nH_0\\text{: Intercept} = 0\n\\] \\[\nH_0\\text{: Slope} = 0\n\\] signifikant sind. Es macht also Sinn diese zu verwerfen.\n\n\n1.1.2.3 Standardisierte Regression\nEine standardisierte lineare Regression setzt wie im Video erklärt voraus, dass alle Variablen z-standardisiert sind. Liegen unvollständige Daten vor, **ist es wichtig diese Standardisierung erst nach dem fallweisen Ausschluss dieser fehlenden Daten zu tun.\n\nmod01 &lt;- lm(scale(g3tmathss) ~ scale(g3classsize), \n            data = data_star_g3aggregated |&gt; \n                # filter rows if g3tmathss or g3classsize is NA\n                filter(!(is.na(g3tmathss) | is.na(g3classsize))))\nsummary(mod01)\n\n\nCall:\nlm(formula = scale(g3tmathss) ~ scale(g3classsize), data = filter(data_star_g3aggregated, \n    !(is.na(g3tmathss) | is.na(g3classsize))))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.82930 -0.76836 -0.01154  0.74300  2.66132 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)         4.284e-16  5.751e-02   0.000   1.0000  \nscale(g3classsize) -1.052e-01  5.761e-02  -1.825   0.0689 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9961 on 298 degrees of freedom\nMultiple R-squared:  0.01106,   Adjusted R-squared:  0.007739 \nF-statistic: 3.332 on 1 and 298 DF,  p-value: 0.06895\n\nextract_eq(mod01, use_coefs = T)\n\n\\[\n\\operatorname{\\widehat{scale(g3tmathss)}} = 0 - 0.11(\\operatorname{scale(g3classsize)})\n\\]\n\n\nDas Intercept wird auf einen Wert mit 14 Nullen nach dem Komma geschätzt, ist also erwartungskonform quasi gleich null und nicht-signifikant. Der Steigungskoeffizient beträgt \\(\\approx .20\\) und liegt nach den Cohen Benchmarks (Cohen 1988) im Bereich kleiner bis moderater Effekte.\nEs gibt Pakete, die darauf spezialisiert sind (mehrere) Regressionsmodelle zusammengefasst übersichtlich in Tabellen darzustellen. Mit der folgenden Syntax bekommt man etwa nicht nur standardisierte und unstandardisierte Koeffizienten, sondern auch deren Konfidenzintervalle, beides auf eine sinnvolle Nachkommestellenanzahl gerundet:\n\nlibrary(sjPlot)\ntab_model(mod00, show.ci = .95, show.std = T)\n\n\n\n\n\n\n\n\n\n\n\n\n \nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\nPredictors\nEstimates\nstd. Beta\nCI\nstandardized CI\np\n\n\n(Intercept)\n642.88\n0.00\n622.87 – 662.89\n-0.11 – 0.11\n&lt;0.001\n\n\nCLASS SIZE GRADE 3\n-0.90\n-0.11\n-1.87 – 0.07\n-0.22 – 0.01\n0.069\n\n\nObservations\n300\n\n\nR2 / R2 adjusted\n0.011 / 0.008",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe",
    "href": "regression.html#aufgabe",
    "title": "1  Regressionsmodelle",
    "section": "1.2 Aufgabe",
    "text": "1.2 Aufgabe\n\nAufgabeLösungshinweiseLösung\n\n\nDas STAR-Experiment variierte die Klassengrößen experimentell in K, G1, G2, G3 & G4. Daten wurden aber bis zu High School erhoben.\nDie Variable g4tmathss etwa erfasst die Mathematikleistung in Klasse 4, die Variablen g4pteffr und g4ptvalu den von Lehrkräften eingeschätzte schulische Leistungsbereitschaft bzw. die Wertschätzung schulischer Inhalte.\nWie groß schätzen Sie die Effekte der Prädiktoren g4pteffr und g4ptvalu ein? Schätzen Sie standardisierte und nicht-standardisierte Regressionsmodelle und diskutieren Sie die interne, externe und Konstruktvalidität der so erhaltenen Befunde.\n\n\n\nlibrary(haven)\nlibrary(sjPlot)\ndata_star_sampled &lt;- read_spss(\"data/data_star_sampled.sav\")\n\nmod02 &lt;- lm(g4tmathss ~ g4pteffr, data = data_star_sampled)\nmod03 &lt;- lm(g4tmathss ~ g4ptvalu, data = data_star_sampled)\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\ntab_model(mod02, mod03, show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n595.70\n0.00\n&lt;0.001\n623.37\n0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:EFFORT\n2.44\n0.60\n&lt;0.001\n\n\n\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:VALUE\n\n\n\n7.07\n0.37\n&lt;0.001\n\n\nObservations\n106\n106\n\n\nR2 / R2 adjusted\n0.357 / 0.351\n0.137 / 0.129\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Effort-Skala ist mit .58 enorm groß ausgeprägt und auch der Effekt des Prädiktors value ist substantiell. Beachtet werden muss allerdings, dass die p-Werte nichts über die Sicherheit der Unterschiedlichkeit der beiden Steigungsparameter aussagt. Getestet wurde jeweils wieder nur die Nullhypothese eines Nulleffekts. Zu kritisieren sind hier sicher interne und Konstruktvalidität. Effort und Value der Schüler:innen wurden von den Lehrkräften ohne vorherige Raterschulung eingeschätzt. Daher ist anzunehmen, dass dieses Rating auch durch die Leistung der Schüler:innen verzerrt ist (z.B. im Sinne eines Haloeffekts, Dennis 2007). Die interne Validität der Schlussfolgerung aus diesen Regressionsmodellen ist schwach, da es sich nur um querschnittliche Daten handelt und die Ausprägung der unabhängigen Variable nicht randomisiert wurde.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#multiple-lineare-regression",
    "href": "regression.html#multiple-lineare-regression",
    "title": "1  Regressionsmodelle",
    "section": "1.3 Multiple lineare Regression",
    "text": "1.3 Multiple lineare Regression\nIn diesem Unterkapitel soll in die multiple Regression eingeführt werden. Dazu dient ebenfalls ein Erklärvideo gefolgt von Aufgaben.\n\n1.3.1 Erklärvideo 1\n\n\n\n\n\n\n\n1.3.2 Erklärvideo 2\nDie standardisierten Steigungskoeffizeinten \\(\\beta_i\\) stellen ja eine Effektstärke der partiellen Assoziation des Prädiktors \\(i\\) mit der abhängigen Variable dar. Nimmt man mehrere Prädiktoren auf, kann der Determinationskoeffizient \\(R^2\\) eine Effektstärke für die Güte des Gesamtmodells darstellen.\n\n\n\n\n\n\n\n1.3.3 Worked Out Example\nIn der Übungsaufgabe zur einfachen linearen Regression haben wir vermutet, dass Einschätzung von Effort und Value durch die Lehrkraft von der Leistung der Lernenden gefärbt sein könnte. Wäre dem so, sollte man ein Sinken der Prädiktionskraft des Prädiktors Value nach Adjustierung um die Vorjahresleistung beobachten.\n\ntab_model(\n    lm(g4tmathss ~ g4ptvalu, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptvalu + g3tmathss, data = data_star_sampled),\n    show.ci = F, show.std = T\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n623.37\n0.00\n&lt;0.001\n183.81\n-0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:VALUE\n7.07\n0.37\n&lt;0.001\n1.37\n0.07\n0.332\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.81\n0.70\n&lt;0.001\n\n\nObservations\n106\n103\n\n\nR2 / R2 adjusted\n0.137 / 0.129\n0.536 / 0.527\n\n\n\n\n\n\n\nDies ist tatsächlich der Fall. Der standardisierte Regressionskoeffizient sinkt von .45 auf .18.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#aufgabe-2",
    "href": "regression.html#aufgabe-2",
    "title": "1  Regressionsmodelle",
    "section": "1.4 Aufgabe",
    "text": "1.4 Aufgabe\n\nAufgabeLösungshinweiseLösung\n\n\nUntersuchen Sie, inwiefern die ebenfalls Lehrer:inneingeschätzte Variable Initiative (z.B. “participates actively in class discussions”) g4ptinit die Mathematikleistung in Klasse 4 g4tmathss prädiziert und inwiefern sich der Effekt nach Adjustierung der Vortestleistung g3tmathss ändernt\n\n\n\nlm(g4tmathss ~ g4ptinit, data = data_star_sampled)\nlm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled)\n\n\n\n\ntab_model(\n    lm(g4tmathss ~ g4ptinit, data = data_star_sampled),\n    lm(g4tmathss ~ g4ptinit + g3tmathss, data = data_star_sampled),\n    show.std = T, show.ci = F)\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\nTOTAL MATH SCALE SCORE\nCTBS GRADE 4\n\n\nPredictors\nEstimates\nstd. Beta\np\nEstimates\nstd. Beta\np\n\n\n(Intercept)\n607.56\n0.00\n&lt;0.001\n255.34\n-0.00\n&lt;0.001\n\n\nGRADE 4 PARTICIPATION\nSUBSCORE:INITIATIVE\n3.89\n0.64\n&lt;0.001\n1.73\n0.28\n0.001\n\n\nTOTAL MATH SCALE SCORE\nSAT GRADE 3\n\n\n\n0.65\n0.56\n&lt;0.001\n\n\nObservations\n106\n103\n\n\nR2 / R2 adjusted\n0.405 / 0.399\n0.583 / 0.575\n\n\n\n\n\n\n\nDer standardisierte Regressionskoeffizient der Initiative-Skala ist mit .49 groß ausgeprägt. Nach Adjustierung um die Vorjahrestestleistung, sinkt die prädiktive Kraft deutlich, es ist aber weiterhin ein substantieller Effekt zu beobachten.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "regression.html#weiterführende-literatur",
    "href": "regression.html#weiterführende-literatur",
    "title": "1  Regressionsmodelle",
    "section": "1.5 Weiterführende Literatur",
    "text": "1.5 Weiterführende Literatur\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema Regression\n\n\n\n\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and Other Stories (1. Aufl.). Cambridge University Press. https://doi.org/10.1017/9781139161879\n\n\n\n\n\n\n\n\nAchilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn, J. Folger, John Johnston, und Elizabeth Word. 1985. „The State of Tennessee’s Student/Teacher Achievement Ratio (STAR) Project“. Technical {{Report}}. Tennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2. Aufl. New Jersey: Lawrence Erlbaum.\n\n\nDennis, Ian. 2007. „Halo Effects in Grading Student Projects“. Journal of Applied Psychology 92 (4): 1169–76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und Varianzanalysen ; mit einem Anhang über Matrixalgebra. 4., vollständig überarbeitete und ergänzte Auflage. Psychologie Lehrtexte. Bern: Verlag Hans Huber.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regressionsmodelle</span>"
    ]
  },
  {
    "objectID": "cfa.html",
    "href": "cfa.html",
    "title": "2  Confirmatory Factor Analysis",
    "section": "",
    "text": "2.1 Items der Participation Subskalen\nDie Items der beiden Skalen haben die folgenden Bezeichnungen:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#items-der-participation-subskalen",
    "href": "cfa.html#items-der-participation-subskalen",
    "title": "2  Confirmatory Factor Analysis",
    "section": "",
    "text": "Participation\n\ng4ptattn: Grade 4 Participation: Pays attention in class\ng8peattn: Grade 8 Participation, English: Pays attention in class\ng8pmattn: Grade 8 Participation, Mathematics: Pays attention in class\ng4ptmtrl: Grade 4 Participation: Loses materials\ng8pemtrl: Grade 8 Participation, English: Loses materials\ng8pmmtrl: Grade 8 Participation, Mathematics: Loses materials\ng4ptpers: Grade 4 Participation: Is persistent\ng8pepers: Grade 8 Participation, English: Is persistent\ng8pmpers: Grade 8 Participation, Mathematics: Is persistent\ng4ptlate: Grade 4 Participation: Comes late to class\ng8pelate: Grade 8 Participation, English: Comes late to class\ng8pmlate: Grade 8 Participation, Mathematics: Comes late to class\n\nInitiative\n\ng4ptmore: Grade 4 Participation: Does extra work\ng8pemore: Grade 8 Participation, English: Does more than assigned work\ng8pmmore: Grade 8 Participation, Mathematics: Does more than assigned work\ng4ptdisc: Grade 4 Participation: Participates in discussions\ng8pedisc: Grade 8 Participation, English: Participates in discussions\ng8pmdisc: Grade 8 Participation, Mathematics: Participates in discussions\ng4ptdiss: Grade 4 Participation: Discusses subject matter outside of class \ng8pediss: Grade 8 Participation, English: Discusses subject matter outside of class\ng8pmdiss: Grade 8 Participation, Mathematics: Discusses subject matter outside of class",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#formelsprache-in-lavaan",
    "href": "cfa.html#formelsprache-in-lavaan",
    "title": "2  Confirmatory Factor Analysis",
    "section": "2.2 Formelsprache in lavaan",
    "text": "2.2 Formelsprache in lavaan\nMit ?model.syntax kann man den folgenden Hilfetext zur Formelsprache in lavaan erhalten:\n\n\n\n\n\n\nFormula-Like Expressions\n\n\n\n\n\nThere can be seven types of formula-like expressions in the model syntax:\n\nLatent variable definitions: The “=~” operator can be used to define (continuous) latent variables. The name of the latent variable is on the left of the “=~” operator, while the terms on the right, separated by “+” operators, are the indicators of the latent variable. The operator “=~” can be read as “is manifested by”.\nRegressions: The “~” operator specifies a regression. The dependent variable is on the left of a “~” operator and the independent variables, separated by “+” operators, are on the right. These regression formulas are similar to the way ordinary linear regression formulas are used in R, but they may include latent variables. Interaction terms are currently not supported.\nVariance-covariances: The “~~” (‘double tilde’) operator specifies (residual) variances of an observed or latent variable, or a set of covariances between one variable, and several other variables (either observed or latent). Several variables, separated by “+” operators can appear on the right. This way, several pairwise (co)variances involving the same left-hand variable can be expressed in a single expression. The distinction between variances and residual variances is made automatically.\nIntercepts: A special case of a regression formula can be used to specify an intercept (or a mean) of either an observed or a latent variable. The variable name is on the left of a “~” operator. On the right is only the number “1” representing the intercept. Including an intercept formula in the model automatically implies meanstructure = TRUE. The distinction between intercepts and means is made automatically.\nThresholds: The “|” operator can be used to define the thresholds of categorical endogenous variables (on the left hand side of the operator). By convention, the thresholds (on the right hand sided, separated by the “+” operator, are named “t1”, “t2”, etcetera.\nScaling factors: The “~*~” operator defines a scale factor. The variable name on the left hand side must be the same as the variable name on the right hand side. Scale factors are used in the Delta parameterization, in a multiple group analysis when factor indicators are categorical.\nFormative factors: The “&lt;~” operator can be used to define a formative factor (on the right hand side of the operator), in a similar way to how a reflexive factor is defined (using the “=~” operator). This is just syntax sugar to define a phantom latent variable (equivalent to using “f =~ 0”). And in addition, the (residual) variance of the formative factor is fixed to zero.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#ein-erstes-cfa-modell",
    "href": "cfa.html#ein-erstes-cfa-modell",
    "title": "2  Confirmatory Factor Analysis",
    "section": "2.3 Ein erstes CFA-Modell",
    "text": "2.3 Ein erstes CFA-Modell",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cfa.html#weiterführende-literatur",
    "href": "cfa.html#weiterführende-literatur",
    "title": "2  Confirmatory Factor Analysis",
    "section": "2.4 Weiterführende Literatur",
    "text": "2.4 Weiterführende Literatur\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema CFA\n\n\n\n\n\n\nEid, M., Gollwitzer, M., & Schmitt, M. (2013). Statistik und Forschungsmethoden: Lehrbuch. Mit Online-Materialien (3. Aufl.). Beltz.\nSacha Epskamp (Regisseur). (2019, April 5). SEM1 (2019)—Stats recap. https://www.youtube.com/watch?v=fGdsiugwO0k\nBrown, T. A. (2015). Confirmatory factor analysis for applied research. Guilford Press.\n\n\n\n\n\n\n\n\nDöring, Nicola, und Jürgen Bortz. 2016. Forschungsmethoden und Evaluation in den Sozial- und Humanwissenschaften. 5., vollst. Berlin, Heidelberg: Springer.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confirmatory Factor Analysis</span>"
    ]
  },
  {
    "objectID": "cross_lagged_panel_models.html",
    "href": "cross_lagged_panel_models.html",
    "title": "3  Cross Lagged Panel Modelle",
    "section": "",
    "text": "3.1 Weiterführende Literatur",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cross Lagged Panel Modelle</span>"
    ]
  },
  {
    "objectID": "cross_lagged_panel_models.html#weiterführende-literatur",
    "href": "cross_lagged_panel_models.html#weiterführende-literatur",
    "title": "3  Cross Lagged Panel Modelle",
    "section": "",
    "text": "Literaturempfehlungen zum Thema Cross Lagged Panel Models\n\n\n\n\n\n\nMackinnon, S., Curtis, R., & O’Connor, R. (2024). A Tutorial in Longitudinal Measurement Invariance and Cross-lagged Panel Models Using lavaan. https://doi.org/10.31234/osf.io/tkzrb\nMcArdle, J. J., & Grimm, K. J. (2010). Five steps in latent curve and latent change score modeling with longitudinal data. In K. van Montfort, J. H. L. Oud, & A. Satorra (Hrsg.), Longitudinal Research with Latent Variables (S. 245–273). Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-11760-2_8",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Cross Lagged Panel Modelle</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html",
    "href": "longitudinal_measurement_invariance.html",
    "title": "4  Längsschnittliche Messinvarianz",
    "section": "",
    "text": "4.1 Konfigurale Invarianz\nlibrary(lavaan)\n\nWarning: package 'lavaan' was built under R version 4.2.3\n\n\nThis is lavaan 0.6-17\nlavaan is FREE software! Please report any bugs.\n\nlibrary(semTools)\n\n \n\n\n###############################################################################\n\n\nThis is semTools 0.5-6\n\n\nAll users of R (or SEM) are invited to submit functions or ideas for functions.\n\n\n###############################################################################\n\nlibrary(semPlot)\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.2.3\n\n# read complete data\ndata_star_selected_variables &lt;- read_spss(\"data/data_star_selected_variables.sav\")\n\npart_configinv_mod &lt;- \n  \"part4e =~ g4ptattn + g4ptmtrl + g4ptpers + g4ptlate\n   part8e =~ g8peattn + g8pemtrl + g8pepers + g8pelate\n\n   # latent (co-)variances\n   part4e ~~ part4e\n   part8e ~~ part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ g4ptattn\n   g4ptmtrl ~~ g4ptmtrl\n   g4ptpers ~~ g4ptpers\n   g4ptlate ~~ g4ptlate\n   g8peattn ~~ g8peattn\n   g8pemtrl ~~ g8pemtrl\n   g8pepers ~~ g8pepers\n   g8pelate ~~ g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\npart_configinv_fit &lt;- \n    cfa(part_configinv_mod, data = data_star_selected_variables)\n\nsemPaths(part_configinv_fit)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Längsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#schwache-invarianz",
    "href": "longitudinal_measurement_invariance.html#schwache-invarianz",
    "title": "4  Längsschnittliche Messinvarianz",
    "section": "4.2 Schwache Invarianz",
    "text": "4.2 Schwache Invarianz\n\npart_weakinv_mod &lt;- \n  \"part4e =~ g4ptattn + s1*g4ptmtrl + s2*g4ptpers + s3*g4ptlate \n   part8e =~ g8peattn + s1*g8pemtrl + s2*g8pepers + s3*g8pelate\n\n   # latent (co-)variances\n   part4e ~~ part4e\n   part8e ~~ part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ g4ptattn\n   g4ptmtrl ~~ g4ptmtrl\n   g4ptpers ~~ g4ptpers\n   g4ptlate ~~ g4ptlate\n   g8peattn ~~ g8peattn\n   g8pemtrl ~~ g8pemtrl\n   g8pepers ~~ g8pepers\n   g8pelate ~~ g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\npart_weakinv_fit &lt;- \n    cfa(part_weakinv_mod, data = data_star_selected_variables)\n\nsemPaths(part_weakinv_fit, what = \"col\")\n\n\n\n\n\n\n\nsemPaths(part_weakinv_fit, what = \"est\", fade = F)\n\n\n\n\n\n\n\nsummary(compareFit(part_configinv_fit, part_weakinv_fit))\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n                   Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\npart_configinv_fit 15 20737 20840 58.125                                       \npart_weakinv_fit   18 20739 20827 66.152     8.0274 0.040673       3    0.04545\n                    \npart_configinv_fit  \npart_weakinv_fit   *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n                     chisq df pvalue rmsea   cfi   tli  srmr        aic\npart_configinv_fit 58.125† 15   .000 .053  .979† .960  .029† 20736.632†\npart_weakinv_fit   66.152  18   .000 .051† .976  .963† .036  20738.660 \n                          bic\npart_configinv_fit 20839.966 \npart_weakinv_fit   20827.232†\n\n################## Differences in Fit Indices #######################\n                                      df  rmsea    cfi   tli  srmr   aic\npart_weakinv_fit - part_configinv_fit  3 -0.002 -0.002 0.003 0.007 2.027\n                                          bic\npart_weakinv_fit - part_configinv_fit -12.735",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Längsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#starke-invarianz",
    "href": "longitudinal_measurement_invariance.html#starke-invarianz",
    "title": "4  Längsschnittliche Messinvarianz",
    "section": "4.3 Starke Invarianz",
    "text": "4.3 Starke Invarianz\n\npart_stronginv_mod &lt;- \n  \"part4e =~ g4ptattn + s1*g4ptmtrl + s2*g4ptpers + s3*g4ptlate \n   part8e =~ g8peattn + s1*g8pemtrl + s2*g8pepers + s3*g8pelate\n\n   # latent (co-)variances with constrains\n   part4e ~~ v1*part4e\n   part8e ~~ v1*part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ g4ptattn\n   g4ptmtrl ~~ g4ptmtrl\n   g4ptpers ~~ g4ptpers\n   g4ptlate ~~ g4ptlate\n   g8peattn ~~ g8peattn\n   g8pemtrl ~~ g8pemtrl\n   g8pepers ~~ g8pepers\n   g8pelate ~~ g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\npart_stronginv_fit &lt;- \n    cfa(part_stronginv_mod, data = data_star_selected_variables)\n\nsemPaths(part_stronginv_fit, what = \"col\")\n\n\n\n\n\n\n\nsemPaths(part_stronginv_fit, what = \"est\", fade = F)\n\n\n\n\n\n\n\nsummary(compareFit(part_configinv_fit, part_weakinv_fit, part_stronginv_fit))\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n                   Df   AIC   BIC  Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)\npart_configinv_fit 15 20737 20840 58.125                                       \npart_weakinv_fit   18 20739 20827 66.152     8.0274 0.040673       3    0.04545\npart_stronginv_fit 19 20737 20820 66.373     0.2203 0.000000       1    0.63879\n                    \npart_configinv_fit  \npart_weakinv_fit   *\npart_stronginv_fit  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n                     chisq df pvalue rmsea   cfi   tli  srmr        aic\npart_configinv_fit 58.125† 15   .000 .053  .979† .960  .029† 20736.632†\npart_weakinv_fit   66.152  18   .000 .051  .976  .963  .036  20738.660 \npart_stronginv_fit 66.373  19   .000 .050† .977  .966† .036  20736.880 \n                          bic\npart_configinv_fit 20839.966 \npart_weakinv_fit   20827.232 \npart_stronginv_fit 20820.531†\n\n################## Differences in Fit Indices #######################\n                                      df  rmsea    cfi   tli  srmr    aic\npart_weakinv_fit - part_configinv_fit  3 -0.002 -0.002 0.003 0.007  2.027\npart_stronginv_fit - part_weakinv_fit  1 -0.002  0.000 0.003 0.000 -1.780\n                                          bic\npart_weakinv_fit - part_configinv_fit -12.735\npart_stronginv_fit - part_weakinv_fit  -6.700",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Längsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#strikte-invarianz",
    "href": "longitudinal_measurement_invariance.html#strikte-invarianz",
    "title": "4  Längsschnittliche Messinvarianz",
    "section": "4.4 Strikte Invarianz",
    "text": "4.4 Strikte Invarianz\n\npart_strictinv_mod &lt;- \n  \"part4e =~ g4ptattn + s1*g4ptmtrl + s2*g4ptpers + s3*g4ptlate \n   part8e =~ g8peattn + s1*g8pemtrl + s2*g8pepers + s3*g8pelate\n\n   # latent (co-)variances with constrains\n   part4e ~~ v1*part4e\n   part8e ~~ v1*part8e\n   part4e ~~ part8e\n   \n   # residual variances\n   g4ptattn ~~ r1*g4ptattn\n   g4ptmtrl ~~ r2*g4ptmtrl\n   g4ptpers ~~ r3*g4ptpers\n   g4ptlate ~~ r4*g4ptlate\n   g8peattn ~~ r1*g8peattn\n   g8pemtrl ~~ r2*g8pemtrl\n   g8pepers ~~ r3*g8pepers\n   g8pelate ~~ r4*g8pelate\n   \n   # set residual covariances free over time per indicator\n   g4ptattn ~~ g8peattn\n   g4ptmtrl ~~ g8pemtrl\n   g4ptpers ~~ g8pepers\n   g4ptlate ~~ g8pelate\n   \"\n\npart_strictinv_fit &lt;- \n    cfa(part_strictinv_mod, data = data_star_selected_variables)\n\nsemPaths(part_strictinv_fit, what = \"col\")\n\n\n\n\n\n\n\nsemPaths(part_strictinv_fit, what = \"est\", fade = F)\n\n\n\n\n\n\n\nsummary(compareFit(part_configinv_fit, part_weakinv_fit, \n                   part_stronginv_fit, part_strictinv_fit))\n\n################### Nested Model Comparison #########################\n\nChi-Squared Difference Test\n\n                   Df   AIC   BIC   Chisq Chisq diff    RMSEA Df diff\npart_configinv_fit 15 20737 20840  58.125                            \npart_weakinv_fit   18 20739 20827  66.152      8.027 0.040673       3\npart_stronginv_fit 19 20737 20820  66.373      0.220 0.000000       1\npart_strictinv_fit 23 20776 20840 113.485     47.113 0.103150       4\n                   Pr(&gt;Chisq)    \npart_configinv_fit               \npart_weakinv_fit      0.04545 *  \npart_stronginv_fit    0.63879    \npart_strictinv_fit  1.445e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n####################### Model Fit Indices ###########################\n                      chisq df pvalue rmsea   cfi   tli  srmr        aic\npart_configinv_fit  58.125† 15   .000 .053  .979† .960  .029† 20736.632†\npart_weakinv_fit    66.152  18   .000 .051  .976  .963  .036  20738.660 \npart_stronginv_fit  66.373  19   .000 .050† .977  .966† .036  20736.880 \npart_strictinv_fit 113.485  23   .000 .062  .955  .946  .049  20775.993 \n                          bic\npart_configinv_fit 20839.966 \npart_weakinv_fit   20827.232 \npart_stronginv_fit 20820.531†\npart_strictinv_fit 20839.961 \n\n################## Differences in Fit Indices #######################\n                                        df  rmsea    cfi    tli  srmr    aic\npart_weakinv_fit - part_configinv_fit    3 -0.002 -0.002  0.003 0.007  2.027\npart_stronginv_fit - part_weakinv_fit    1 -0.002  0.000  0.003 0.000 -1.780\npart_strictinv_fit - part_stronginv_fit  4  0.013 -0.021 -0.020 0.013 39.113\n                                            bic\npart_weakinv_fit - part_configinv_fit   -12.735\npart_stronginv_fit - part_weakinv_fit    -6.700\npart_strictinv_fit - part_stronginv_fit  19.430",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Längsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "longitudinal_measurement_invariance.html#weiterführende-literatur",
    "href": "longitudinal_measurement_invariance.html#weiterführende-literatur",
    "title": "4  Längsschnittliche Messinvarianz",
    "section": "4.5 Weiterführende Literatur",
    "text": "4.5 Weiterführende Literatur\n\n\n\n\n\n\nLiteraturempfehlungen zum Thema Longitudinal Measurement Invariance\n\n\n\n\n\n\nMackinnon, S., Curtis, R., & O’Connor, R. (2024). A Tutorial in Longitudinal Measurement Invariance and Cross-lagged Panel Models Using lavaan. https://doi.org/10.31234/osf.io/tkzrb\nBrown, T. A. (2015). Confirmatory factor analysis for applied research. Guilford Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Längsschnittliche Messinvarianz</span>"
    ]
  },
  {
    "objectID": "latent_change_score_models.html",
    "href": "latent_change_score_models.html",
    "title": "5  Latent Change Score Models",
    "section": "",
    "text": "library(lavaan)\n\nWarning: package 'lavaan' was built under R version 4.2.3\n\n\nThis is lavaan 0.6-17\nlavaan is FREE software! Please report any bugs.\n\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.2.3\n\nlibrary(semPlot)\n\n# read complete data\ndata_star &lt;- read_spss(\"data/STAR_Students.sav\")\n\nFailed to find G1READ_A\nFailed to find G1MATH_A\nFailed to find G2READ_A\nFailed to find G2MATH_A\nFailed to find G3READ_A\nFailed to find G3MATH_A\n\n# read selected variables\ndata_star_selected_variables &lt;- \n    read_spss(\"data/data_star_selected_variables.sav\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Latent Change Score Models</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Achilles, C. M., Helen Pate Bain, F. Bellot, J. Boyd-Zaharias, J. Finn,\nJ. Folger, John Johnston, and Elizabeth Word. 1985. “The State of\nTennessee’s Student/Teacher Achievement Ratio\n(STAR) Project.” Technical {{Report}}.\nTennessee State Department of Educatbn.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. New Jersey: Lawrence\nErlbaum.\n\n\nDennis, Ian. 2007. “Halo Effects in Grading Student\nProjects.” Journal of Applied Psychology 92 (4):\n1169–76. https://doi.org/10.1037/0021-9010.92.4.1169.\n\n\nDöring, Nicola, and Jürgen Bortz. 2016. Forschungsmethoden und\nEvaluation in den Sozial- und Humanwissenschaften. 5.,\nvollst. Berlin, Heidelberg: Springer.\n\n\nMoosbrugger, Helfried. 2011. Lineare Modelle: Regressions- und\nVarianzanalysen ; mit einem Anhang über\nMatrixalgebra. 4., vollständig\nüberarbeitete und ergänzte Auflage.\nPsychologie Lehrtexte. Bern: Verlag Hans\nHuber.",
    "crumbs": [
      "Literatur"
    ]
  }
]